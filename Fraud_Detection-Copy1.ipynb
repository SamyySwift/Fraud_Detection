{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection\n",
    "\n",
    "This notebook uses the credit card fraud detection dataset, and explores different binary classification models that can identify transactions as either fraudulent or valid, based on provided, *historical* data.\n",
    "\n",
    "### Dataset Info\n",
    "\n",
    "The payment fraud data set was downloaded from [Kaggle](https://www.kaggle.com/mlg-ulb/creditcardfraud/data). This has features and labels for thousands of credit card transactions, each of which is labeled as fraudulent or valid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, recall_score, accuracy_score, precision_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Exploring the Data\n",
    "\n",
    "Next, I am loading the data and unzipping the data in the file `creditcardfraud.zip`. This directory will hold one csv file of all the transaction data, `creditcard.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape (rows, cols):  (284807, 31)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the csv file\n",
    "local_data = 'creditcard.csv'\n",
    "\n",
    "# print out some data\n",
    "transaction_df = pd.read_csv(local_data)\n",
    "print('Data shape (rows, cols): ', transaction_df.shape)\n",
    "print()\n",
    "transaction_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "# check for importantant information\n",
    "transaction_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>1.168375e-15</td>\n",
       "      <td>3.416908e-16</td>\n",
       "      <td>-1.379537e-15</td>\n",
       "      <td>2.074095e-15</td>\n",
       "      <td>9.604066e-16</td>\n",
       "      <td>1.487313e-15</td>\n",
       "      <td>-5.556467e-16</td>\n",
       "      <td>1.213481e-16</td>\n",
       "      <td>-2.406331e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.654067e-16</td>\n",
       "      <td>-3.568593e-16</td>\n",
       "      <td>2.578648e-16</td>\n",
       "      <td>4.473266e-15</td>\n",
       "      <td>5.340915e-16</td>\n",
       "      <td>1.683437e-15</td>\n",
       "      <td>-3.660091e-16</td>\n",
       "      <td>-1.227390e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  1.168375e-15  3.416908e-16 -1.379537e-15  2.074095e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   9.604066e-16  1.487313e-15 -5.556467e-16  1.213481e-16 -2.406331e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  1.654067e-16 -3.568593e-16  2.578648e-16  4.473266e-15   \n",
       "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   5.340915e-16  1.683437e-15 -3.660091e-16 -1.227390e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transaction_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for class imbalance\n",
    "We can see that there's  indeed a huge amount of class imbalance. We'll need to balance this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAD4CAYAAAAZ1BptAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAARaklEQVR4nO3cf6zddX3H8edrrTg2f1ClEka7lWhjUoxWqIhzOicJFNxS3BBhiTSGWBMh0UQzUZNVURL5Q8lYtAmOhmKUH0EJTayrDeIMSxAuikBBxg3CaINQaQUdUwa+98f5NByu53Pv7a97S+/zkZyc73l/P5/P93Oac++r38/3e26qCkmSRvmj2Z6AJOngZUhIkroMCUlSlyEhSeoyJCRJXfNnewL725FHHllLliyZ7WlI0ovKHXfc8cuqWjixfsiFxJIlSxgbG5vtaUjSi0qSh0fVXW6SJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1HXLfuN4XSy78zmxPQQeph774ntmegjQrPJOQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUteUIZFkcZKbk9ybZGuSj7b6Z5NsT3Jne5w+1OdTScaT3J/k1KH6ylYbT3LhUP3YJD9q9WuTHNbqL22vx9v+Jfv13UuSJjWdM4lngY9X1TLgJOD8JMvavkuranl7bAJo+84GjgNWAl9NMi/JPOArwGnAMuCcoXEuaWO9DtgFnNfq5wG7Wv3S1k6SNEOmDImqerSqfty2fw3cBxwzSZdVwDVV9buq+jkwDpzYHuNV9WBVPQNcA6xKEuDdwPWt/wbgjKGxNrTt64GTW3tJ0gzYo2sSbbnnzcCPWumCJHclWZ9kQasdAzwy1G1bq/XqrwZ+VVXPTqi/YKy2/8nWfuK81iQZSzK2Y8eOPXlLkqRJTDskkrwM+Bbwsap6ClgHvBZYDjwKfOlATHA6quryqlpRVSsWLlw4W9OQpEPOtEIiyUsYBMQ3qurbAFX1WFU9V1W/B77GYDkJYDuweKj7olbr1Z8Ajkgyf0L9BWO1/a9s7SVJM2A6dzcFuAK4r6q+PFQ/eqjZe4F72vZG4Ox2Z9KxwFLgNuB2YGm7k+kwBhe3N1ZVATcDZ7b+q4Ebh8Za3bbPBL7f2kuSZsD8qZvwduADwN1J7my1TzO4O2k5UMBDwIcBqmprkuuAexncGXV+VT0HkOQCYDMwD1hfVVvbeJ8ErknyBeAnDEKJ9vz1JOPATgbBIkmaIVOGRFXdAoy6o2jTJH0uBi4eUd80ql9VPcjzy1XD9d8C75tqjpKkA8NvXEuSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6poyJJIsTnJzknuTbE3y0VZ/VZItSR5ozwtaPUkuSzKe5K4kxw+Ntbq1fyDJ6qH6CUnubn0uS5LJjiFJmhnTOZN4Fvh4VS0DTgLOT7IMuBC4qaqWAje11wCnAUvbYw2wDga/8IG1wFuBE4G1Q7/01wEfGuq3stV7x5AkzYApQ6KqHq2qH7ftXwP3AccAq4ANrdkG4Iy2vQq4qgZuBY5IcjRwKrClqnZW1S5gC7Cy7XtFVd1aVQVcNWGsUceQJM2APbomkWQJ8GbgR8BRVfVo2/UL4Ki2fQzwyFC3ba02WX3biDqTHGPivNYkGUsytmPHjj15S5KkSUw7JJK8DPgW8LGqemp4XzsDqP08txeY7BhVdXlVraiqFQsXLjyQ05CkOWVaIZHkJQwC4htV9e1WfqwtFdGeH2/17cDioe6LWm2y+qIR9cmOIUmaAdO5uynAFcB9VfXloV0bgd13KK0Gbhyqn9vucjoJeLItGW0GTkmyoF2wPgXY3PY9leSkdqxzJ4w16hiSpBkwfxpt3g58ALg7yZ2t9mngi8B1Sc4DHgbOavs2AacD48DTwAcBqmpnks8Dt7d2F1XVzrb9EeBK4HDgu+3BJMeQJM2AKUOiqm4B0tl98oj2BZzfGWs9sH5EfQx4w4j6E6OOIUmaGX7jWpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlS15QhkWR9kseT3DNU+2yS7UnubI/Th/Z9Ksl4kvuTnDpUX9lq40kuHKofm+RHrX5tksNa/aXt9Xjbv2S/vWtJ0rRM50ziSmDliPqlVbW8PTYBJFkGnA0c1/p8Ncm8JPOArwCnAcuAc1pbgEvaWK8DdgHntfp5wK5Wv7S1kyTNoClDoqp+COyc5nirgGuq6ndV9XNgHDixPcar6sGqega4BliVJMC7getb/w3AGUNjbWjb1wMnt/aSpBmyL9ckLkhyV1uOWtBqxwCPDLXZ1mq9+quBX1XVsxPqLxir7X+ytZckzZC9DYl1wGuB5cCjwJf214T2RpI1ScaSjO3YsWM2pyJJh5S9Comqeqyqnquq3wNfY7CcBLAdWDzUdFGr9epPAEckmT+h/oKx2v5Xtvaj5nN5Va2oqhULFy7cm7ckSRphr0IiydFDL98L7L7zaSNwdrsz6VhgKXAbcDuwtN3JdBiDi9sbq6qAm4EzW//VwI1DY61u22cC32/tJUkzZP5UDZJcDbwLODLJNmAt8K4ky4ECHgI+DFBVW5NcB9wLPAucX1XPtXEuADYD84D1VbW1HeKTwDVJvgD8BLii1a8Avp5knMGF87P39c1KkvbMlCFRVeeMKF8xora7/cXAxSPqm4BNI+oP8vxy1XD9t8D7ppqfJOnA8RvXkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUteUIZFkfZLHk9wzVHtVki1JHmjPC1o9SS5LMp7kriTHD/VZ3do/kGT1UP2EJHe3PpclyWTHkCTNnOmcSVwJrJxQuxC4qaqWAje11wCnAUvbYw2wDga/8IG1wFuBE4G1Q7/01wEfGuq3copjSJJmyJQhUVU/BHZOKK8CNrTtDcAZQ/WrauBW4IgkRwOnAluqamdV7QK2ACvbvldU1a1VVcBVE8YadQxJ0gzZ22sSR1XVo237F8BRbfsY4JGhdttabbL6thH1yY7xB5KsSTKWZGzHjh178XYkSaPs84XrdgZQ+2Eue32Mqrq8qlZU1YqFCxceyKlI0pyytyHxWFsqoj0/3urbgcVD7Ra12mT1RSPqkx1DkjRD9jYkNgK771BaDdw4VD+33eV0EvBkWzLaDJySZEG7YH0KsLnteyrJSe2upnMnjDXqGJKkGTJ/qgZJrgbeBRyZZBuDu5S+CFyX5DzgYeCs1nwTcDowDjwNfBCgqnYm+Txwe2t3UVXtvhj+EQZ3UB0OfLc9mOQYkqQZMmVIVNU5nV0nj2hbwPmdcdYD60fUx4A3jKg/MeoYkqSZ4zeuJUldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR17VNIJHkoyd1J7kwy1mqvSrIlyQPteUGrJ8llScaT3JXk+KFxVrf2DyRZPVQ/oY0/3vpmX+YrSdoz++NM4m+qanlVrWivLwRuqqqlwE3tNcBpwNL2WAOsg0GoAGuBtwInAmt3B0tr86Ghfiv3w3wlSdN0IJabVgEb2vYG4Iyh+lU1cCtwRJKjgVOBLVW1s6p2AVuAlW3fK6rq1qoq4KqhsSRJM2BfQ6KA7yW5I8maVjuqqh5t278AjmrbxwCPDPXd1mqT1beNqP+BJGuSjCUZ27Fjx768H0nSkPn72P+vqmp7ktcAW5L8bHhnVVWS2sdjTKmqLgcuB1ixYsUBP54kzRX7dCZRVdvb8+PADQyuKTzWlopoz4+35tuBxUPdF7XaZPVFI+qSpBmy1yGR5E+TvHz3NnAKcA+wEdh9h9Jq4Ma2vRE4t93ldBLwZFuW2gyckmRBu2B9CrC57XsqyUntrqZzh8aSJM2AfVluOgq4od2VOh/4ZlX9e5LbgeuSnAc8DJzV2m8CTgfGgaeBDwJU1c4knwdub+0uqqqdbfsjwJXA4cB320OSNEP2OiSq6kHgTSPqTwAnj6gXcH5nrPXA+hH1MeANeztHSdK+8RvXkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUtdBHxJJVia5P8l4kgtnez6SNJcc1CGRZB7wFeA0YBlwTpJlszsrSZo75s/2BKZwIjBeVQ8CJLkGWAXcO6uzkmbJkgu/M9tT0EHsoS++Z7+PebCHxDHAI0OvtwFvndgoyRpgTXv5myT3z8Dc5oIjgV/O9iQOBrlktmegDj+jQ/bxc/oXo4oHe0hMS1VdDlw+2/M41CQZq6oVsz0PqcfP6IF3UF+TALYDi4deL2o1SdIMONhD4nZgaZJjkxwGnA1snOU5SdKccVAvN1XVs0kuADYD84D1VbV1lqc1l7iEp4Odn9EDLFU123OQJB2kDvblJknSLDIkJEldhsQckuTmJKdOqH0sybpO+x8kWdG2NyU5YkSbzyb5xAGZsF60kjyX5M6hx5IDcIyHkhw5RZsrk5y5l+MvT3L63s3u0HFQX7jWfnc1gzvENg/Vzgb+aaqOVTXnf1i0R/63qpaP2pEkDK6H/n5mp7THlgMrgE2zPI9Z5ZnE3HI98J52OzHtf3d/xuBvYo0l2Zrkc6M6Dv+vLclnkvxXkluA18/Q3PUilmRJ+0OdVwH3AIuTrBv1uZvwWVuR5Adt+9VJvtfa/xuQobHvGer/iSSfHTGHE5L8R5I7kmxOcnSr/yDJJUlua5/rd7SfkYuA97czofcfsH+cg5whMYdU1U7gNgZ/MBEGZxHXAZ9p31p9I/DXSd7YGyPJCa3fcuB04C0Hcs560Tp8aKnphlZbCny1qo6rqofZg89dsxa4paqOA24A/ny6k0nyEuBfgTOr6gRgPXDxUJP5VXUi8DFgbVU9A/wzcG1VLa+qa6d7rEONy01zz+4lpxvb83nAWe3vX80HjmbwF3fv6vR/B3BDVT0NkMQvN2qUFyw3tbPWh6vq1qE2e/K5A3gn8PcAVfWdJLv2YD6vB94AbBmsdjEPeHRo/7fb8x3Akj0Y95BnSMw9NwKXJjke+BNgJ/AJ4C1VtSvJlcAfz+L8dOj6n90bSY6l/7l7ludXOabzWRxu3+sTYGtVva0zxu/a83P4e/EFXG6aY6rqN8DNDE63rwZeweCH98kkR/H8UlTPD4Ezkhye5OXA3x3I+eqQNdnn7iHghLb9D0P1HwL/CJDkNGBBqz8GvKZds3gp8Lcjjnc/sDDJ21r/lyQ5boo5/hp4+bTf0SHKkJibrgbeBFxdVT8FfgL8DPgm8J+TdayqHwPXAj8Fvsvg72tJe2SKz93ngH9JMsbgf/bD9Xcm2cpg2em/21j/x+Ai823AljbmxOM9A5wJXJLkp8CdwF9OMc2bgWVz/cK1f5ZDktTlmYQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSer6fylY+fw0yXlpAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(transaction_df['Class'].unique(), transaction_df['Class'].value_counts(), tick_label = ['Valid', 'Fraudulent']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the percentage of fraudulent data\n",
    "\n",
    "Take a look at the distribution of this transaction data over the classes, valid and fraudulent. \n",
    "\n",
    "The function `fraudulent_percentage`, below, Counts up the number of data points in each class and calculate the *percentage* of the data points that are fraudulent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the fraction of data points that are fraudulent\n",
    "def fraudulent_percentage(transaction_df):\n",
    "    '''Calculate the fraction of all data points that have a 'Class' label of 1; fraudulent.\n",
    "       :param transaction_df: Dataframe of all transaction data points; has a column 'Class'\n",
    "       :return: A fractional percentage of fraudulent data points/all points\n",
    "    '''\n",
    "    \n",
    "    # your code here\n",
    "    all_data_points = len(transaction_df.Class)\n",
    "    fraudulent_data_points = len(transaction_df.Class[transaction_df.Class==1])\n",
    "    \n",
    "    fraudulent_percentage = fraudulent_data_points/all_data_points\n",
    "    \n",
    "    return fraudulent_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraudulent percentage = 0.17%\n",
      "Total # of fraudulent pts:  492.0\n",
      "Out of (total) pts:  284807\n"
     ]
    }
   ],
   "source": [
    "# call the function to calculate the fraud percentage\n",
    "fraud_percentage = fraudulent_percentage(transaction_df)\n",
    "\n",
    "print(f'Fraudulent percentage = {round(fraud_percentage*100, 2)}%')\n",
    "print('Total # of fraudulent pts: ', fraud_percentage*transaction_df.shape[0])\n",
    "print('Out of (total) pts: ', transaction_df.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into train/test datasets\n",
    "So, we'll need to split the data into separate training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get features\n",
    "features = transaction_df.iloc[:, :-1]\n",
    "# Get labels\n",
    "labels = transaction_df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, labels, train_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a helper function to check for performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_check(y_test, x_test, model):\n",
    "    \"\"\"\n",
    "    Helper function to help check for performance\n",
    "    \"\"\"\n",
    "    print(classification_report(y_test, model.predict(x_test)))\n",
    "    print('-----------------------------------------------------')\n",
    "    print('Confusion Matrix\\n')\n",
    "    print(confusion_matrix(y_test,  model.predict(x_test)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "1. Gradient Boosting Classifier\n",
    "3. Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the Gradient Boosting model\n",
    "gradient_boost = GradientBoostingClassifier()\n",
    "\n",
    "# Fit on the train and test set\n",
    "gradient_boost.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    227459\n",
      "           1       0.92      0.63      0.75       387\n",
      "\n",
      "    accuracy                           1.00    227846\n",
      "   macro avg       0.96      0.81      0.87    227846\n",
      "weighted avg       1.00      1.00      1.00    227846\n",
      "\n",
      "-----------------------------------------------------\n",
      "Confusion Matrix\n",
      "\n",
      "[[227439     20]\n",
      " [   145    242]]\n"
     ]
    }
   ],
   "source": [
    "# Check for performance\n",
    "performance_check(y_test, x_test, gradient_boost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the XGB model\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "# Fit on the train and test set\n",
    "xgb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    227459\n",
      "           1       0.94      0.75      0.84       387\n",
      "\n",
      "    accuracy                           1.00    227846\n",
      "   macro avg       0.97      0.88      0.92    227846\n",
      "weighted avg       1.00      1.00      1.00    227846\n",
      "\n",
      "-----------------------------------------------------\n",
      "Confusion Matrix\n",
      "\n",
      "[[227440     19]\n",
      " [    96    291]]\n"
     ]
    }
   ],
   "source": [
    "# Check for performance\n",
    "performance_check(y_test, x_test, xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try an Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(64, input_shape=(x_train.shape[1],), activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 64)                1984      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,097\n",
      "Trainable params: 4,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1781/1781 [==============================] - 60s 33ms/step - loss: 24.1081 - accuracy: 0.9938 - val_loss: 6.9947 - val_accuracy: 0.9983\n",
      "Epoch 2/3\n",
      "1781/1781 [==============================] - 59s 33ms/step - loss: 9.5335 - accuracy: 0.9959 - val_loss: 15.8246 - val_accuracy: 0.9983\n",
      "Epoch 3/3\n",
      "1781/1781 [==============================] - 59s 33ms/step - loss: 9.1859 - accuracy: 0.9964 - val_loss: 8.8951 - val_accuracy: 0.9983\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2162f0e4100>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit and train the model on train data\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), batch_size=32, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7121/7121 [==============================] - 27s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(x_test)\n",
    "pred = np.where(pred < 0.5, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    227459\n",
      "           1       0.20      0.00      0.01       387\n",
      "\n",
      "    accuracy                           1.00    227846\n",
      "   macro avg       0.60      0.50      0.50    227846\n",
      "weighted avg       1.00      1.00      1.00    227846\n",
      "\n",
      "-----------------------------------------------------\n",
      "Confusion Matrix\n",
      "\n",
      "[[227455      4]\n",
      " [   386      1]]\n"
     ]
    }
   ],
   "source": [
    "# Check for performance ANN\n",
    "print(classification_report(y_test, pred))\n",
    "print('-----------------------------------------------------')\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion_matrix(y_test,  pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Improvements\n",
    "\n",
    "Both the Gradient Boosting and Artificial Neural Network got a high accuracy, but still mis-classified fraudulent and valid data points. From the `Confusion Matrix` above, you can clearly see the Gradient Boosting, classifying more than 100 points as false negatives (incorrectly labelled fraudulent transactions), 24 points as false positives (incorrectly labelled, valid transactions).\n",
    "\n",
    "**1. Model optimization**\n",
    "* Since we want a model that will catch almost *all* cases of fraudulent transactions, even if it means a higher number of false positives(valid incorrectly labelled as fradulent), then we'd want as few **false negatives** as possible, hence we do not want to optimize for accuracy only. Instead, we want to optimize for a metric that can help us decrease the number of **false negatives**.\n",
    "\n",
    "**2. Imbalanced training data**\n",
    "* The dataset is quite imbalanced, were only about 0.17% of the training data was labeled as fraudulent. So, even if a model labels **all** of our data as valid, it will still have a high accuracy. \n",
    "* This may result in some overfitting towards valid data, which accounts for some **false negatives**; cases in which fraudulent data (1) is incorrectly classified as valid (0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Balancing imblanced data by downsampling the majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Counter({0: 56856, 1: 105})\n",
      "After Counter({0: 105, 1: 105})\n"
     ]
    }
   ],
   "source": [
    "# Use counter to count number of samples in the target column\n",
    "counter = Counter(y_train)\n",
    "print('Before', counter)\n",
    "\n",
    "# Instantiate the RandomUndersampler()\n",
    "under_sample = RandomUnderSampler()\n",
    "\n",
    "# Undersample the majority\n",
    "X_train_ru, y_train_ru = under_sample.fit_resample(x_train, y_train)\n",
    "counter = Counter(y_train_ru)\n",
    "print('After',counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit a new model on balanced data\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train_ru, y_train_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99    227459\n",
      "           1       0.06      0.89      0.12       387\n",
      "\n",
      "    accuracy                           0.98    227846\n",
      "   macro avg       0.53      0.93      0.55    227846\n",
      "weighted avg       1.00      0.98      0.99    227846\n",
      "\n",
      "-----------------------------------------------------\n",
      "Confusion Matrix\n",
      "\n",
      "[[222310   5149]\n",
      " [    44    343]]\n"
     ]
    }
   ],
   "source": [
    "performance_check(y_test, x_test, xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After, balancing the imbalanced class by downsampling the majority class, we see that the model improved greatly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After undersampling, we can see that we have improved the false negativa score from 72% to 88%, and reduced the misclassified points to 46.\n",
    "\n",
    "Let's explore which features are most important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary of different algorithms \n",
    "models = {\n",
    "        'XGBoostClassifier':XGBClassifier(),\n",
    "        'GradientBoostingClassifier':GradientBoostingClassifier(),\n",
    "        'RandomForest':RandomForestClassifier(),\n",
    "        'DecisionTreesClassifier':DecisionTreeClassifier(),\n",
    "        'ExtraTreesClassifier':ExtraTreesClassifier(),\n",
    "        'AdaBoostClassifier':AdaBoostClassifier()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper funtion to compute the score, RMSE, time on the training and testing set\n",
    "\n",
    "def pipeline(models, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    This function iteratively goes through all the models defined in the dictionary and \n",
    "    computes the Train_score, Test_score, MSE, MAE and RMSE.\n",
    "    \n",
    "    Parameters: model, training set(X_train), test_set(X_test), train_labels(y_train), and test_labels(y_test).\n",
    "    \n",
    "    Returns: This funtion returns a dataFrame containing calculations of each models and also plots bar\n",
    "            chart showing how each models performs.\n",
    "    \"\"\"\n",
    "    \n",
    "    # store properties of each model\n",
    "    prop = []\n",
    "    \n",
    "    # loop through the dictionary of models\n",
    "    for clf_name, model in models.items():\n",
    "        # empty dict for storing properties of each models\n",
    "        clf_dict = {}\n",
    "        # store the name of each model\n",
    "        clf_dict['Name'] = clf_name\n",
    "        # fit the regressor model\n",
    "        model.fit(X_train, y_train)\n",
    "        # compute the Train_score\n",
    "        clf_dict['Train_score'] = model.score(X_train, y_train)\n",
    "        # compute the test scores\n",
    "        clf_dict['Test_score'] = model.score(X_test, y_test)\n",
    "        # compute the accuracy\n",
    "        clf_dict['Accuracy'] = round(accuracy_score(y_test, model.predict(x_test)), 3)\n",
    "        #compute the recall score\n",
    "        clf_dict['Recall'] = round(recall_score(y_test, model.predict(x_test)), 3)\n",
    "        # compute the precision score\n",
    "        clf_dict['Precision'] = round(precision_score(y_test, model.predict(x_test)), 3)\n",
    "     \n",
    "        # append the properties of a single regressor to the prop list\n",
    "        prop.append(clf_dict)\n",
    "     \n",
    "    # create a dataframe with a list of all the model properties\n",
    "    summary_df = pd.DataFrame(prop)\n",
    "        \n",
    "        \n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Train_score</th>\n",
       "      <th>Test_score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoostClassifier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.977208</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.962944</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.989401</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreesClassifier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.882754</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993342</td>\n",
       "      <td>0.993</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.956879</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Name  Train_score  Test_score  Accuracy  Recall  \\\n",
       "0           XGBoostClassifier          1.0    0.977208     0.977   0.886   \n",
       "1  GradientBoostingClassifier          1.0    0.962944     0.963   0.876   \n",
       "2                RandomForest          1.0    0.989401     0.989   0.868   \n",
       "3     DecisionTreesClassifier          1.0    0.882754     0.883   0.881   \n",
       "4        ExtraTreesClassifier          1.0    0.993342     0.993   0.871   \n",
       "5          AdaBoostClassifier          1.0    0.956879     0.957   0.884   \n",
       "\n",
       "   Precision  \n",
       "0      0.062  \n",
       "1      0.039  \n",
       "2      0.124  \n",
       "3      0.013  \n",
       "4      0.187  \n",
       "5      0.034  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# execute the function\n",
    "pipeline(models, X_train_ru, x_test, y_train_ru, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "# get feature importance\n",
    "feature_importance = pd.Series(RF.feature_importances_, index=x_train.columns)\n",
    "feature_importance.nlargest(15).plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get names of top 15 features\n",
    "indices = np.argsort(feature_importance)[::-1]\n",
    "names = [x_train.columns[i] for i in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use top 10 features to train new model\n",
    "x_train_best = x_train[names[0:10]]\n",
    "x_test_best = x_test[names[0:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Counter({0: 56856, 1: 105})\n",
      "After Counter({0: 105, 1: 105})\n"
     ]
    }
   ],
   "source": [
    "counter = Counter(y_train)\n",
    "print('Before', counter)\n",
    "\n",
    "under_sample = RandomUnderSampler()\n",
    "\n",
    "X_train_ru, y_train_ru = under_sample.fit_resample(x_train_best, y_train)\n",
    "\n",
    "counter = Counter(y_train_ru)\n",
    "print('After',counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a Random Forest on the new downsampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-17 {color: black;background-color: white;}#sk-container-id-17 pre{padding: 0;}#sk-container-id-17 div.sk-toggleable {background-color: white;}#sk-container-id-17 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-17 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-17 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-17 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-17 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-17 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-17 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-17 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-17 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-17 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-17 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-17 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-17 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-17 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-17 div.sk-item {position: relative;z-index: 1;}#sk-container-id-17 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-17 div.sk-item::before, #sk-container-id-17 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-17 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-17 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-17 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-17 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-17 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-17 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-17 div.sk-label-container {text-align: center;}#sk-container-id-17 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-17 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-17\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" checked><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF = RandomForestClassifier()\n",
    "RF.fit(X_train_ru, y_train_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99    227459\n",
      "           1       0.07      0.88      0.12       387\n",
      "\n",
      "    accuracy                           0.98    227846\n",
      "   macro avg       0.53      0.93      0.56    227846\n",
      "weighted avg       1.00      0.98      0.99    227846\n",
      "\n",
      "-----------------------------------------------------\n",
      "Confusion Matrix\n",
      "\n",
      "[[222650   4809]\n",
      " [    46    341]]\n"
     ]
    }
   ],
   "source": [
    "performance_check(y_test, x_test_best, RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(RF, open('RF_model.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "notice": "None."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
