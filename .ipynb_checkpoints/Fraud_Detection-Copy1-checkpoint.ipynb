{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection\n",
    "\n",
    "This notebook uses the credit card fraud detection dataset, and explores different binary classification models that can identify transactions as either fraudulent or valid, based on provided, *historical* data.\n",
    "\n",
    "### Dataset Info\n",
    "\n",
    "The payment fraud data set was downloaded from [Kaggle](https://www.kaggle.com/mlg-ulb/creditcardfraud/data). This has features and labels for thousands of credit card transactions, each of which is labeled as fraudulent or valid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, recall_score, accuracy_score, precision_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Exploring the Data\n",
    "\n",
    "Next, I am loading the data and unzipping the data in the file `creditcardfraud.zip`. This directory will hold one csv file of all the transaction data, `creditcard.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape (rows, cols):  (284807, 31)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the csv file\n",
    "local_data = 'creditcard.csv'\n",
    "\n",
    "# print out some data\n",
    "transaction_df = pd.read_csv(local_data)\n",
    "print('Data shape (rows, cols): ', transaction_df.shape)\n",
    "print()\n",
    "transaction_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "# check for importantant information\n",
    "transaction_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>1.168375e-15</td>\n",
       "      <td>3.416908e-16</td>\n",
       "      <td>-1.379537e-15</td>\n",
       "      <td>2.074095e-15</td>\n",
       "      <td>9.604066e-16</td>\n",
       "      <td>1.487313e-15</td>\n",
       "      <td>-5.556467e-16</td>\n",
       "      <td>1.213481e-16</td>\n",
       "      <td>-2.406331e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.654067e-16</td>\n",
       "      <td>-3.568593e-16</td>\n",
       "      <td>2.578648e-16</td>\n",
       "      <td>4.473266e-15</td>\n",
       "      <td>5.340915e-16</td>\n",
       "      <td>1.683437e-15</td>\n",
       "      <td>-3.660091e-16</td>\n",
       "      <td>-1.227390e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  1.168375e-15  3.416908e-16 -1.379537e-15  2.074095e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   9.604066e-16  1.487313e-15 -5.556467e-16  1.213481e-16 -2.406331e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  1.654067e-16 -3.568593e-16  2.578648e-16  4.473266e-15   \n",
       "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   5.340915e-16  1.683437e-15 -3.660091e-16 -1.227390e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transaction_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for class imbalance\n",
    "We can see that there's  indeed a huge amount of class imbalance. We'll need to balance this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(transaction_df['Class'].unique(), transaction_df['Class'].value_counts(), tick_label = ['Valid', 'Fraudulent']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the percentage of fraudulent data\n",
    "\n",
    "Take a look at the distribution of this transaction data over the classes, valid and fraudulent. \n",
    "\n",
    "The function `fraudulent_percentage`, below, Counts up the number of data points in each class and calculate the *percentage* of the data points that are fraudulent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the fraction of data points that are fraudulent\n",
    "def fraudulent_percentage(transaction_df):\n",
    "    '''Calculate the fraction of all data points that have a 'Class' label of 1; fraudulent.\n",
    "       :param transaction_df: Dataframe of all transaction data points; has a column 'Class'\n",
    "       :return: A fractional percentage of fraudulent data points/all points\n",
    "    '''\n",
    "    \n",
    "    # your code here\n",
    "    all_data_points = len(transaction_df.Class)\n",
    "    fraudulent_data_points = len(transaction_df.Class[transaction_df.Class==1])\n",
    "    \n",
    "    fraudulent_percentage = fraudulent_data_points/all_data_points\n",
    "    \n",
    "    return fraudulent_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraudulent percentage = 0.17%\n",
      "Total # of fraudulent pts:  492.0\n",
      "Out of (total) pts:  284807\n"
     ]
    }
   ],
   "source": [
    "# call the function to calculate the fraud percentage\n",
    "fraud_percentage = fraudulent_percentage(transaction_df)\n",
    "\n",
    "print(f'Fraudulent percentage = {round(fraud_percentage*100, 2)}%')\n",
    "print('Total # of fraudulent pts: ', fraud_percentage*transaction_df.shape[0])\n",
    "print('Out of (total) pts: ', transaction_df.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into train/test datasets\n",
    "So, we'll need to split the data into separate training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get features\n",
    "features = transaction_df.iloc[:, :-1]\n",
    "# Get labels\n",
    "labels = transaction_df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, labels, train_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a helper function to check for performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_check(y_test, x_test, model):\n",
    "    \"\"\"\n",
    "    Helper function to help check for performance\n",
    "    \"\"\"\n",
    "    print(classification_report(y_test, model.predict(x_test)))\n",
    "    print('-----------------------------------------------------')\n",
    "    print('Confusion Matrix\\n')\n",
    "    print(confusion_matrix(y_test,  model.predict(x_test)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "1. Gradient Boosting Classifier\n",
    "2. XGBoost\n",
    "3. Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the Gradient Boosting model\n",
    "gradient_boost = GradientBoostingClassifier()\n",
    "\n",
    "# Fit on the train and test set\n",
    "gradient_boost.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    227459\n",
      "           1       0.92      0.63      0.74       387\n",
      "\n",
      "    accuracy                           1.00    227846\n",
      "   macro avg       0.96      0.81      0.87    227846\n",
      "weighted avg       1.00      1.00      1.00    227846\n",
      "\n",
      "-----------------------------------------------------\n",
      "Confusion Matrix\n",
      "\n",
      "[[227437     22]\n",
      " [   145    242]]\n"
     ]
    }
   ],
   "source": [
    "# Check for performance\n",
    "performance_check(y_test, x_test, gradient_boost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the XGB model\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "# Fit on the train and test set\n",
    "xgb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    227459\n",
      "           1       0.94      0.75      0.84       387\n",
      "\n",
      "    accuracy                           1.00    227846\n",
      "   macro avg       0.97      0.88      0.92    227846\n",
      "weighted avg       1.00      1.00      1.00    227846\n",
      "\n",
      "-----------------------------------------------------\n",
      "Confusion Matrix\n",
      "\n",
      "[[227440     19]\n",
      " [    96    291]]\n"
     ]
    }
   ],
   "source": [
    "# Check for performance\n",
    "performance_check(y_test, x_test, xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try an Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(64, input_shape=(x_train.shape[1],), activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                1984      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,097\n",
      "Trainable params: 4,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1781/1781 [==============================] - 11s 6ms/step - loss: 77.6596 - accuracy: 0.9887 - val_loss: 5.8007 - val_accuracy: 0.9983\n",
      "Epoch 2/3\n",
      "1781/1781 [==============================] - 10s 5ms/step - loss: 9.9408 - accuracy: 0.9957 - val_loss: 20.8425 - val_accuracy: 0.9983\n",
      "Epoch 3/3\n",
      "1781/1781 [==============================] - 10s 6ms/step - loss: 10.0682 - accuracy: 0.9967 - val_loss: 1.4412 - val_accuracy: 0.9982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28c49083bb0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit and train the model on train data\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), batch_size=32, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7121/7121 [==============================] - 8s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(x_test)\n",
    "pred = np.where(pred < 0.5, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    227459\n",
      "           1       0.19      0.02      0.04       387\n",
      "\n",
      "    accuracy                           1.00    227846\n",
      "   macro avg       0.59      0.51      0.52    227846\n",
      "weighted avg       1.00      1.00      1.00    227846\n",
      "\n",
      "-----------------------------------------------------\n",
      "Confusion Matrix\n",
      "\n",
      "[[227421     38]\n",
      " [   378      9]]\n"
     ]
    }
   ],
   "source": [
    "# Check for performance ANN\n",
    "print(classification_report(y_test, pred))\n",
    "print('-----------------------------------------------------')\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion_matrix(y_test,  pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Improvements\n",
    "\n",
    "Both the Gradient Boosting and Artificial Neural Network got a high accuracy, but still mis-classified fraudulent and valid data points. From the `Confusion Matrix` above, you can clearly see the Gradient Boosting, classifying more than 100 points as false negatives (incorrectly labelled fraudulent transactions), 24 points as false positives (incorrectly labelled, valid transactions).\n",
    "\n",
    "**1. Model optimization**\n",
    "* Since we want a model that will catch almost *all* cases of fraudulent transactions, even if it means a higher number of false positives(valid incorrectly labelled as fradulent), then we'd want as few **false negatives** as possible, hence we do not want to optimize for accuracy only. Instead, we want to optimize for a metric that can help us decrease the number of **false negatives**.\n",
    "\n",
    "**2. Imbalanced training data**\n",
    "* The dataset is quite imbalanced, were only about 0.17% of the training data was labeled as fraudulent. So, even if a model labels **all** of our data as valid, it will still have a high accuracy. \n",
    "* This may result in some overfitting towards valid data, which accounts for some **false negatives**; cases in which fraudulent data (1) is incorrectly classified as valid (0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Balancing imblanced data by downsampling the majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Counter({0: 56856, 1: 105})\n",
      "After Counter({0: 105, 1: 105})\n"
     ]
    }
   ],
   "source": [
    "# Use counter to count number of samples in the target column\n",
    "counter = Counter(y_train)\n",
    "print('Before', counter)\n",
    "\n",
    "# Instantiate the RandomUndersampler()\n",
    "under_sample = RandomUnderSampler()\n",
    "\n",
    "# Undersample the majority\n",
    "X_train_ru, y_train_ru = under_sample.fit_resample(x_train, y_train)\n",
    "counter = Counter(y_train_ru)\n",
    "print('After',counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit a new model on balanced data\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train_ru, y_train_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98    227459\n",
      "           1       0.03      0.88      0.06       387\n",
      "\n",
      "    accuracy                           0.95    227846\n",
      "   macro avg       0.52      0.92      0.52    227846\n",
      "weighted avg       1.00      0.95      0.97    227846\n",
      "\n",
      "-----------------------------------------------------\n",
      "Confusion Matrix\n",
      "\n",
      "[[217060  10399]\n",
      " [    45    342]]\n"
     ]
    }
   ],
   "source": [
    "performance_check(y_test, x_test, xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After, balancing the imbalanced class by downsampling the majority class, we see that the model improved greatly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After undersampling, we can see that we have improved the false negativa score from 72% to 88%, and reduced the misclassified points to 46.\n",
    "\n",
    "Let's explore which features are most important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary of different algorithms \n",
    "models = {\n",
    "        'XGBoostClassifier':XGBClassifier(),\n",
    "        'GradientBoostingClassifier':GradientBoostingClassifier(),\n",
    "        'RandomForest':RandomForestClassifier(),\n",
    "        'DecisionTreesClassifier':DecisionTreeClassifier(),\n",
    "        'ExtraTreesClassifier':ExtraTreesClassifier(),\n",
    "        'AdaBoostClassifier':AdaBoostClassifier()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper funtion to compute the score, RMSE, time on the training and testing set\n",
    "\n",
    "def pipeline(models, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    This function iteratively goes through all the models defined in the dictionary and \n",
    "    computes the Train_score, Test_score, MSE, MAE and RMSE.\n",
    "    \n",
    "    Parameters: model, training set(X_train), test_set(X_test), train_labels(y_train), and test_labels(y_test).\n",
    "    \n",
    "    Returns: This funtion returns a dataFrame containing calculations of each models and also plots bar\n",
    "            chart showing how each models performs.\n",
    "    \"\"\"\n",
    "    \n",
    "    # store properties of each model\n",
    "    prop = []\n",
    "    \n",
    "    # loop through the dictionary of models\n",
    "    for clf_name, model in models.items():\n",
    "        # empty dict for storing properties of each models\n",
    "        clf_dict = {}\n",
    "        # store the name of each model\n",
    "        clf_dict['Name'] = clf_name\n",
    "        # fit the regressor model\n",
    "        model.fit(X_train, y_train)\n",
    "        # compute the Train_score\n",
    "        clf_dict['Train_score'] = model.score(X_train, y_train)\n",
    "        # compute the test scores\n",
    "        clf_dict['Test_score'] = model.score(X_test, y_test)\n",
    "        # compute the accuracy\n",
    "        clf_dict['Accuracy'] = round(accuracy_score(y_test, model.predict(x_test)), 3)\n",
    "        #compute the recall score\n",
    "        clf_dict['Recall'] = round(recall_score(y_test, model.predict(x_test)), 3)\n",
    "        # compute the precision score\n",
    "        clf_dict['Precision'] = round(precision_score(y_test, model.predict(x_test)), 3)\n",
    "     \n",
    "        # append the properties of a single regressor to the prop list\n",
    "        prop.append(clf_dict)\n",
    "     \n",
    "    # create a dataframe with a list of all the model properties\n",
    "    summary_df = pd.DataFrame(prop)\n",
    "        \n",
    "        \n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Train_score</th>\n",
       "      <th>Test_score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoostClassifier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.954162</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.965117</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.983669</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreesClassifier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.867244</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.991161</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.951621</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Name  Train_score  Test_score  Accuracy  Recall  \\\n",
       "0           XGBoostClassifier          1.0    0.954162     0.954   0.884   \n",
       "1  GradientBoostingClassifier          1.0    0.965117     0.965   0.879   \n",
       "2                RandomForest          1.0    0.983669     0.984   0.873   \n",
       "3     DecisionTreesClassifier          1.0    0.867244     0.867   0.881   \n",
       "4        ExtraTreesClassifier          1.0    0.991161     0.991   0.868   \n",
       "5          AdaBoostClassifier          1.0    0.951621     0.952   0.886   \n",
       "\n",
       "   Precision  \n",
       "0      0.032  \n",
       "1      0.041  \n",
       "2      0.084  \n",
       "3      0.011  \n",
       "4      0.146  \n",
       "5      0.030  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# execute the function\n",
    "pipeline(models, X_train_ru, x_test, y_train_ru, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "# get feature importance\n",
    "feature_importance = pd.Series(xgb.feature_importances_, index=x_train.columns)\n",
    "feature_importance.nlargest(15).plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get names of top 15 features\n",
    "indices = np.argsort(feature_importance)[::-1]\n",
    "names = [x_train.columns[i] for i in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use top 10 features to train new model\n",
    "x_train_best = x_train[names[0:10]]\n",
    "x_test_best = x_test[names[0:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Counter({0: 56856, 1: 105})\n",
      "After Counter({0: 105, 1: 105})\n"
     ]
    }
   ],
   "source": [
    "counter = Counter(y_train)\n",
    "print('Before', counter)\n",
    "\n",
    "under_sample = RandomUnderSampler()\n",
    "\n",
    "X_train_ru, y_train_ru = under_sample.fit_resample(x_train_best, y_train)\n",
    "\n",
    "counter = Counter(y_train_ru)\n",
    "print('After',counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a Random Forest on the new downsampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XG = XGBClassifier()\n",
    "XG.fit(X_train_ru, y_train_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98    227459\n",
      "           1       0.04      0.87      0.08       387\n",
      "\n",
      "    accuracy                           0.97    227846\n",
      "   macro avg       0.52      0.92      0.53    227846\n",
      "weighted avg       1.00      0.97      0.98    227846\n",
      "\n",
      "-----------------------------------------------------\n",
      "Confusion Matrix\n",
      "\n",
      "[[219791   7668]\n",
      " [    49    338]]\n"
     ]
    }
   ],
   "source": [
    "performance_check(y_test, x_test_best, XG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(XG, open('XGB_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "notice": "None."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
